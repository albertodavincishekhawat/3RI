{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preRequisite\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[GFG Stats CheatSheet](https://www.geeksforgeeks.org/statistics-cheatsheet/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03.07.2024 Class\n",
    "# [**Hypothesis Testing?**](https://www.simplilearn.com/tutorials/statistics-tutorial/hypothesis-testing-in-statistics)\n",
    "\n",
    "[Examples and calculations of z-test & t-test pdf](files/z-test-and-t-test.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> In analytics it's very very very important to check all statistics of data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why do it ?\n",
    "We want to know if sample data is right representation of sample data or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try to learn about statistics of sample data.\n",
    "- sample = subset of population data\n",
    "\n",
    "\n",
    ">statistics such as mean, median, std.dev etc.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hypo-testing is mostly done on sample data and not population data. <br>\n",
    "\n",
    ">all though sample mean is compared with population mean.(while doing certain tests)\n",
    "\n",
    ">first priority is to check if mean of the sample data is true or not. Is it too far away from population mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Hypothesis that there is no difference between things is called NULL HYPOTHESIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process of testing if **H_null(significant)** is true or **H_alter(byChance)** is True **Hypothesis Testing**.\n",
    "> Testing is done by tests such as t-test, z-test, Chi-Square test etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ex. problem :** mean of height of people in pune is 165 cm.\n",
    "- we we find out if the value of mean is significant or fluke(by chance)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ex. problem :** exam of 50 students in which 25 students score above 80%\n",
    "- we check if 80% is true or fluke."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ex.problem** : Average spending pune people on shopping is Rs10300 p/m  \n",
    "- is average spending really Rs 10300 pm or not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Such testings are important because, let us understand relaiblity of data!\n",
    "\n",
    "> **If no alpha given always consider 0.05**\n",
    "\n",
    "> **computedValue < tabularValue = nullHypothesis is right**\n",
    "\n",
    "> **computedValue > tabularValue = nullHypothesis is wrong**\n",
    "\n",
    "> **If difference of computedValue and tabularValue is not more than or less than 2 to 3 points then we accept the null hypothsis** its an industry practice by calling it \"critical region\". (not to be done with health care data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Z-test?\n",
    "- Applied on large data, more than or equal 30 samples.\n",
    "- And Population StandardDeviation is given.\n",
    "> **In practical if Std.dev is  not available** \n",
    "- We will still go with z-test if no. of records are high.\n",
    "- We use Std.Dev of Sample data in place of StdDev of population data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inception of the Z-test, a fundamental statistical tool, can be traced back to the development of statistical theory and practice in the early 20th century. Here’s a brief overview of its origin and significance:\n",
    "\n",
    "### The Origin of Z-Test\n",
    "\n",
    "1. **Early Statistical Development:**\n",
    "   - The foundations of the Z-test lie in the work on the normal distribution by Carl Friedrich Gauss in the early 19th century. The normal distribution, also known as the Gaussian distribution, became a cornerstone in statistical theory due to its properties and prevalence in natural phenomena.\n",
    "\n",
    "2. **The Central Limit Theorem:**\n",
    "   - The Central Limit Theorem (CLT), developed in the late 19th century, played a crucial role. The CLT states that the distribution of the sample mean approaches a normal distribution as the sample size grows, regardless of the population's distribution. This theorem provided the theoretical basis for the Z-test.\n",
    "\n",
    "3. **Development by William Sealy Gosset:**\n",
    "   - In the early 1900s, William Sealy Gosset, under the pseudonym \"Student,\" developed the Student's t-test. The Z-test can be seen as a specific case of the t-test applied when the population variance is known and the sample size is large.\n",
    "\n",
    "4. **Ronald A. Fisher and Statistical Methods:**\n",
    "   - Sir Ronald A. Fisher, a key figure in the development of modern statistics, contributed to the formalization and popularization of various statistical tests, including the Z-test, through his work in the 1920s and 1930s. Fisher's work on hypothesis testing and significance testing laid the groundwork for the practical application of the Z-test.\n",
    "\n",
    "#### Significance of the Z-Test\n",
    "\n",
    "1. **Hypothesis Testing:**\n",
    "   - The Z-test is widely used in hypothesis testing to determine if there is a significant difference between sample and population means, or between the means of two samples. It helps in making inferences about population parameters based on sample data.\n",
    "\n",
    "2. **Applications in Various Fields:**\n",
    "   - The Z-test is utilized in numerous fields, including psychology, medicine, economics, and engineering, for tasks such as quality control, clinical trials, and survey analysis.\n",
    "\n",
    "3. **Basis for Other Statistical Tests:**\n",
    "   - The principles of the Z-test form the basis for many other statistical tests and procedures, making it a fundamental tool in the arsenal of statisticians and researchers.\n",
    "\n",
    "#### Conclusion\n",
    "\n",
    "The Z-test, with its roots in the development of the normal distribution and the Central Limit Theorem, has become an essential statistical tool thanks to contributions from early statisticians like Gauss, Gosset, and Fisher. Its ability to facilitate hypothesis testing and its wide applicability across various fields underscore its importance in statistical analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z-TEST FOR ONE SAMPLE MEAN?\n",
    "> Two tail test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    ">Z-test for One Sample Formula<br>\n",
    "![Z-testFormula](Images/Ztest1SampleFormula.PNG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Z-table for refrence\n",
    "\n",
    "> significance = alpha\n",
    "\n",
    "![Ztable](Images/Z-table.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEPS IN TESTING HYPOTHESIS \n",
    "\n",
    "Below are the steps when testing the truth of a hypothesis.\n",
    "1. Formulate the null hypothesis. Denote it as Ho and the alternativehypothesis as Ha.\n",
    "2. Set the desired level of significance (alpha).\n",
    "3. Determine the appropriate test statistic to be used in testing thenull hypothesis.\n",
    "4. Compute for the value of the statistic to be used.\n",
    "5. Compute for the degrees of freedom and tabular/critical values.\n",
    "6. Make the decision by comparing the computed value and critical/tabular value.\n",
    "7. State the conclusion/implication.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z-TEST FOR TWO SAMPLE MEAN?\n",
    "> one tailed test\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "• Is used when comparing two separate\n",
    "samples drawn at random taken from\n",
    "a normal population\n",
    "\n",
    "• Used to test whether the difference\n",
    "between the two values of MeanOfSample1 and\n",
    "MeanOfSample2 is significant or can be attributed\n",
    "to chance.\n",
    "\n",
    "![alt](Images/Ztest2SampleFormula.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T-test?\n",
    "- Applied on small data, less than 30 records.\n",
    "- Or Population Standard Deviation is not given. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The t-test, also known as Student's t-test, was developed in the early 20th century and has become a fundamental tool in statistical analysis. Here’s a brief overview of its origin and significance:\n",
    "\n",
    "### The Origin of the T-Test\n",
    "\n",
    "1. **William Sealy Gosset:**\n",
    "   - The t-test was developed by William Sealy Gosset, a British chemist and statistician who worked for the Guinness Brewery in Dublin. Due to the brewery's policy on publishing research, Gosset published his work under the pseudonym \"Student\" in 1908, leading to the term \"Student's t-test.\"\n",
    "\n",
    "2. **Motivation:**\n",
    "   - Gosset's motivation was to address issues related to small sample sizes. At Guinness, Gosset needed a reliable method to ensure the quality of stout without wasting large quantities of product. Existing methods were inadequate for small sample sizes, prompting Gosset to develop a new statistical approach.\n",
    "\n",
    "3. **Publication:**\n",
    "   - Gosset published his findings in a paper titled \"The Probable Error of a Mean\" in the journal Biometrika. In this paper, he introduced the t-distribution, which adjusts for the increased variability that occurs in small samples.\n",
    "\n",
    "#### Significance of the T-Test\n",
    "\n",
    "1. **Handling Small Samples:**\n",
    "   - The t-test is particularly useful for small sample sizes where the normal distribution approximation may not be accurate. It provides a way to make inferences about population parameters with more precision in these cases.\n",
    "\n",
    "2. **Different Forms:**\n",
    "   - There are several forms of the t-test, including:\n",
    "     - **One-sample t-test:** Tests whether the mean of a single sample differs significantly from a known or hypothesized population mean.\n",
    "     - **Independent two-sample t-test:** Compares the means of two independent samples to determine if they come from populations with equal means.\n",
    "     - **Paired sample t-test:** Compares the means of two related groups to determine if there is a significant difference between them.\n",
    "\n",
    "3. **Applications:**\n",
    "   - The t-test is widely used in various fields such as psychology, medicine, biology, and social sciences. It is employed in clinical trials, psychological testing, and many other research areas to determine if observed data deviate significantly from expectations.\n",
    "\n",
    "4. **Basis for Further Developments:**\n",
    "   - The t-test and the associated t-distribution have influenced the development of other statistical methods and tests. They provide a foundation for more complex analyses and contribute to the broader field of inferential statistics.\n",
    "\n",
    "#### Conclusion\n",
    "\n",
    "The t-test, developed by William Sealy Gosset under the pseudonym \"Student,\" addressed the need for reliable statistical methods for small sample sizes. Its creation marked a significant advancement in statistical theory and practice, providing a versatile and widely applicable tool for hypothesis testing and inferential statistics. The t-test's development has had a lasting impact, influencing subsequent statistical methodologies and applications across diverse fields."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### One Sample Test\n",
    "Two Tail Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two Sample Test\n",
    "One Tail Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two Tail Test vs One Tail Test\n",
    "\n",
    "> tails means number of posiblities ~kind off\n",
    "\n",
    "**One tailed test** means if compared mean is  higher than refrence mean hypothesis is true or if its lower than reference mean hypothesis is true depending on the nature of hypothesis.\n",
    "\n",
    "But in case of **Two tailed test** hypothesis if compared mean is not significant to refrence mean i.e, more or less the same then null hypothesis is true if its significant in either direction then then null hypothesis is not true, viceversa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion : z-test t-test, one sample test two sample test, one tailed test two tailed test\n",
    "### Overview of Z-Test and T-Test\n",
    "\n",
    "#### Z-Test\n",
    "- **Purpose**: Used to determine if there is a significant difference between sample data and population data, often when the population variance is known or the sample size is large (n > 30).\n",
    "- **Assumptions**:\n",
    "  - The data follows a normal distribution.\n",
    "  - Population variance is known.\n",
    "  - Large sample size (n > 30).\n",
    "\n",
    "\n",
    "#### T-Test\n",
    "- **Purpose**: Used to determine if there is a significant difference between sample data and population data, or between two sample means, particularly when the population variance is unknown and the sample size is small (n ≤ 30).\n",
    "- **Assumptions**:\n",
    "  - The data follows a normal distribution.\n",
    "  - Population variance is unknown.\n",
    "- **Types**:\n",
    "  - **One-Sample T-Test**\n",
    "  - **Two-Sample T-Test** (Independent or Paired)\n",
    "\n",
    "### One-Sample T-Test vs. Two-Sample T-Test\n",
    "\n",
    "#### One-Sample T-Test\n",
    "- **Purpose**: Determines whether the mean of a single sample differs significantly from a known or hypothesized population mean.\n",
    "- **Hypotheses**:\n",
    "  - Null hypothesis : The sample mean is equal to the population mean.\n",
    "  - Alternative hypothesis : The sample mean is not equal to the population mean.\n",
    "\n",
    "\n",
    "#### Two-Sample T-Test\n",
    "- **Purpose**: Compares the means of two independent samples to determine if they are significantly different from each other.\n",
    "- **Hypotheses**:\n",
    "  - Null hypothesis : The means of the two samples are equal.\n",
    "  - Alternative hypothesis : The means of the two samples are not equal.\n",
    "- **Types**:\n",
    "  - **Independent Two-Sample T-Test**: Compares means from two different groups.\n",
    "  - **Paired Sample T-Test**: Compares means from the same group at different times (e.g., before and after treatment).\n",
    "\n",
    "\n",
    "### One-Tailed Test vs. Two-Tailed Test\n",
    "\n",
    "#### One-Tailed Test\n",
    "- **Purpose**: Tests for the possibility of the relationship in one direction and disregards the possibility of a relationship in the other direction.\n",
    "- **Hypotheses**:\n",
    "  - For a one-sample t-test:\n",
    "    - Right-tailed: \\(\\mu > \\mu_0\\)\n",
    "    - Left-tailed: \\(\\mu < \\mu_0\\)\n",
    "  - For a two-sample t-test:\n",
    "    - Right-tailed: \\(\\mu_1 > \\mu_2\\)\n",
    "    - Left-tailed: \\(\\mu_1 < \\mu_2\\)\n",
    "- **Example Use Case**:\n",
    "  - One-sample: Testing if a new drug increases reaction times (one direction).\n",
    "  - Two-sample: Comparing the effectiveness of two drugs where the new drug is expected to be more effective.\n",
    "\n",
    "#### Two-Tailed Test\n",
    "- **Purpose**: Tests for the possibility of a relationship in both directions.\n",
    "- **Hypotheses**:\n",
    "  - For a one-sample t-test:\n",
    "    - Null hypothesis (\\(H_0\\)): \\(\\mu = \\mu_0\\)\n",
    "    - Alternative hypothesis (\\(H_A\\)): \\(\\mu \\ne \\mu_0\\)\n",
    "  - For a two-sample t-test:\n",
    "    - Null hypothesis (\\(H_0\\)): \\(\\mu_1 = \\mu_2\\)\n",
    "    - Alternative hypothesis (\\(H_A\\)): \\(\\mu_1 \\ne \\mu_2\\)\n",
    "- **Example Use Case**:\n",
    "  - One-sample: Testing if the average weight of a product is different from the target value.\n",
    "  - Two-sample: Comparing test scores of two teaching methods without a specific direction of expectation.\n",
    "\n",
    "### Summary\n",
    "\n",
    "#### Z-Test\n",
    "- **When to Use**: Large sample sizes, known population variance.\n",
    "- **Formula**: \\[\n",
    "  z = \\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}}\n",
    "  \\]\n",
    "\n",
    "#### T-Test\n",
    "- **When to Use**: Small sample sizes, unknown population variance.\n",
    "- **Types**:\n",
    "  - **One-Sample T-Test**: \\[\n",
    "  t = \\frac{\\bar{X} - \\mu_0}{s / \\sqrt{n}}\n",
    "  \\]\n",
    "  - **Two-Sample T-Test**: \\[\n",
    "  t = \\frac{\\bar{X}_1 - \\bar{X}_2}{\\sqrt{s_p^2 \\left( \\frac{1}{n_1} + \\frac{1}{n_2} \\right)}}\n",
    "  \\]\n",
    "\n",
    "#### One-Tailed Test\n",
    "- **Purpose**: Tests in one direction.\n",
    "- **Example Hypotheses**:\n",
    "  - \\(H_0: \\mu \\leq \\mu_0\\) vs. \\(H_A: \\mu > \\mu_0\\)\n",
    "\n",
    "#### Two-Tailed Test\n",
    "- **Purpose**: Tests in both directions.\n",
    "- **Example Hypotheses**:\n",
    "  - \\(H_0: \\mu = \\mu_0\\) vs. \\(H_A: \\mu \\ne \\mu_0\\)\n",
    "\n",
    "By understanding these different tests and when to use them, you can accurately determine if there are significant differences or relationships in your data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04.07.2024 Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Chi-square test is a non-parametric statistical test used to determine if there is a significant association between categorical variables. It compares the observed frequencies of events to the expected frequencies under the null hypothesis. Here’s an overview of the Chi-square test and its sub-tests:\n",
    "\n",
    "### Chi-Square Test\n",
    "\n",
    "#### Purpose:\n",
    "- To assess whether observed frequencies differ significantly from expected frequencies in one or more categories.\n",
    "\n",
    "#### Assumptions:\n",
    "- The data are in the form of frequencies or counts of cases.\n",
    "- The sample size is large enough (typically, each expected frequency should be 5 or more).\n",
    "- The observations are independent.\n",
    "\n",
    "### Types of Chi-Square Tests\n",
    "\n",
    "1. **Chi-Square Goodness-of-Fit Test**\n",
    "2. **Chi-Square Test of Independence**\n",
    "3. **Chi-Square Test of Homogeneity**\n",
    "\n",
    "### 1. Chi-Square Goodness-of-Fit Test\n",
    "\n",
    "#### Purpose:\n",
    "- To determine if a sample data matches a population with a specific distribution.\n",
    "\n",
    "#### Hypotheses:\n",
    "- Null hypothesis (\\(H_0\\)): The observed frequencies match the expected frequencies.\n",
    "- Alternative hypothesis (\\(H_A\\)): The observed frequencies do not match the expected frequencies.\n",
    "\n",
    "#### Formula:\n",
    "- The test statistic for the Chi-square goodness-of-fit test is calculated as:\n",
    "  \\[\n",
    "  \\chi^2 = \\sum \\frac{(O_i - E_i)^2}{E_i}\n",
    "  \\]\n",
    "  where:\n",
    "  - \\(O_i\\) is the observed frequency for category \\(i\\),\n",
    "  - \\(E_i\\) is the expected frequency for category \\(i\\).\n",
    "\n",
    "#### Example Use Case:\n",
    "- A die is rolled 60 times, and the outcomes are recorded. To determine if the die is fair, compare the observed frequencies of each face with the expected frequencies (which should be equal if the die is fair).\n",
    "\n",
    "### 2. Chi-Square Test of Independence\n",
    "\n",
    "#### Purpose:\n",
    "- To determine if there is a significant association between two categorical variables.\n",
    "\n",
    "#### Hypotheses:\n",
    "- Null hypothesis (\\(H_0\\)): The two variables are independent (no association).\n",
    "- Alternative hypothesis (\\(H_A\\)): The two variables are not independent (there is an association).\n",
    "\n",
    "#### Formula:\n",
    "- The test statistic for the Chi-square test of independence is calculated similarly to the goodness-of-fit test, but using a contingency table:\n",
    "  \\[\n",
    "  \\chi^2 = \\sum \\frac{(O_{ij} - E_{ij})^2}{E_{ij}}\n",
    "  \\]\n",
    "  where:\n",
    "  - \\(O_{ij}\\) is the observed frequency for cell \\(ij\\),\n",
    "  - \\(E_{ij}\\) is the expected frequency for cell \\(ij\\), calculated as:\n",
    "    \\[\n",
    "    E_{ij} = \\frac{(row\\ total\\ for\\ cell\\ ij \\times column\\ total\\ for\\ cell\\ ij)}{grand\\ total}\n",
    "    \\]\n",
    "\n",
    "#### Example Use Case:\n",
    "- A survey is conducted to determine if there is an association between gender (male/female) and preference for a new product (like/dislike). A contingency table is created, and the test is used to determine if preference is independent of gender.\n",
    "\n",
    "### 3. Chi-Square Test of Homogeneity\n",
    "\n",
    "#### Purpose:\n",
    "- To determine if different populations have the same distribution of a categorical variable.\n",
    "\n",
    "#### Hypotheses:\n",
    "- Null hypothesis (\\(H_0\\)): The distributions of the categorical variable are the same across different populations.\n",
    "- Alternative hypothesis (\\(H_A\\)): The distributions of the categorical variable are not the same across different populations.\n",
    "\n",
    "#### Formula:\n",
    "- The test statistic for the Chi-square test of homogeneity is calculated similarly to the test of independence, using a contingency table:\n",
    "  \\[\n",
    "  \\chi^2 = \\sum \\frac{(O_{ij} - E_{ij})^2}{E_{ij}}\n",
    "  \\]\n",
    "  where:\n",
    "  - \\(O_{ij}\\) is the observed frequency for cell \\(ij\\),\n",
    "  - \\(E_{ij}\\) is the expected frequency for cell \\(ij\\), calculated similarly to the test of independence.\n",
    "\n",
    "#### Example Use Case:\n",
    "- Comparing the distribution of different types of feedback (positive/negative/neutral) across different departments in a company. The test determines if the distribution of feedback types is homogeneous across departments.\n",
    "\n",
    "### Summary\n",
    "\n",
    "#### Chi-Square Goodness-of-Fit Test\n",
    "- **Purpose**: Tests if the observed frequencies match the expected frequencies in a single categorical variable.\n",
    "- **Formula**: \\[\n",
    "  \\chi^2 = \\sum \\frac{(O_i - E_i)^2}{E_i}\n",
    "  \\]\n",
    "- **Use Case**: Checking if a die is fair.\n",
    "\n",
    "#### Chi-Square Test of Independence\n",
    "- **Purpose**: Tests if there is an association between two categorical variables.\n",
    "- **Formula**: \\[\n",
    "  \\chi^2 = \\sum \\frac{(O_{ij} - E_{ij})^2}{E_{ij}}\n",
    "  \\]\n",
    "- **Use Case**: Checking if gender is associated with product preference.\n",
    "\n",
    "#### Chi-Square Test of Homogeneity\n",
    "- **Purpose**: Tests if different populations have the same distribution of a categorical variable.\n",
    "- **Formula**: \\[\n",
    "  \\chi^2 = \\sum \\frac{(O_{ij} - E_{ij})^2}{E_{ij}}\n",
    "  \\]\n",
    "- **Use Case**: Comparing feedback distribution across different departments.\n",
    "\n",
    "The Chi-square test and its sub-tests are powerful tools for analyzing categorical data, helping to determine if observed patterns differ significantly from expectations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chi-Square test?\n",
    "\n",
    "### Why use it?\n",
    "Used to test independence of categorical columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex.Problem\n",
    "Hypothesis to test!<br>\n",
    "![alt](Images/chiSquareHypothesis.PNG)<br>\n",
    "Data available <br>\n",
    "![alt](Images/chiSquareRefData.PNG)<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method?\n",
    "- First find observed values \n",
    "\n",
    "- then, find expected values\n",
    "\n",
    "- then calculate ChiSquare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### observed values\n",
    "![alt](Images/chiSquareObservedData.PNG)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **ExpectedValue**\n",
    "= rowTotal * columnTotal / totalValues\n",
    "\n",
    "![alt](Images/chiSquareExpected.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **ChiSquare Value**\n",
    "![alt](Images/chiSquareValue.PNG)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Degree Of Freedom**\n",
    "![alt](Images/chiSquareCountDegreeOfFreedom.PNG)<br>\n",
    "![alt](Images/chiSquaredegreeOfFreedom.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Tabular Value**\n",
    "check value of alpha on ChiSquare table\n",
    "\n",
    "![alt](Images/chiSquareTabularValue.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compare ChiSquareValue with TabularAlphaValue(from ChiSquare table)\n",
    "![alt](Images/chiSquareValueCompareAlphaValue.PNG)\n",
    "\n",
    "##### **ChiSquareValue less than TabularAlphaValue so Null Hypothesis is true.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-Square Value: 2.0335997362886893\n",
      "P-Value: 0.7295788445264156\n",
      "Degrees of Freedom: 4\n",
      "Expected Frequencies:\n",
      " [[12.26277372 18.83211679 28.90510949]\n",
      " [ 6.54014599 10.04379562 15.41605839]\n",
      " [ 9.19708029 14.12408759 21.67883212]]\n",
      "Is Significant: False\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "def calculate_chi_square(matrix, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Calculate the chi-square value from a given matrix and check for statistical significance.\n",
    "    \n",
    "    Parameters:\n",
    "    matrix (list of lists): The input matrix\n",
    "    alpha (float): The significance level (default is 0.05)\n",
    "    \n",
    "    Returns:\n",
    "    dict: A dictionary containing the chi-square value, p-value, degrees of freedom,\n",
    "          expected frequencies, and significance result.\n",
    "    \"\"\"\n",
    "    matrix = np.array(matrix)\n",
    "    chi2, p, dof, expected = chi2_contingency(matrix)\n",
    "    is_significant = p <= alpha\n",
    "    result = {\n",
    "        \"Chi-Square Value\": chi2,\n",
    "        \"P-Value\": p,\n",
    "        \"Degrees of Freedom\": dof,\n",
    "        \"Expected Frequencies\": expected,\n",
    "        \"Is Significant\": is_significant\n",
    "    }\n",
    "    return result\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Example matrix input\n",
    "    matrix = [\n",
    "        [10, 20, 30],\n",
    "        [6,  9,  17],\n",
    "        [12, 14, 19]\n",
    "    ]\n",
    "    \n",
    "    result = calculate_chi_square(matrix)\n",
    "    print(\"Chi-Square Value:\", result[\"Chi-Square Value\"])\n",
    "    print(\"P-Value:\", result[\"P-Value\"])\n",
    "    print(\"Degrees of Freedom:\", result[\"Degrees of Freedom\"])\n",
    "    print(\"Expected Frequencies:\\n\", result[\"Expected Frequencies\"])\n",
    "    print(\"Is Significant:\", result[\"Is Significant\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [**Central Limit Theorm**](https://www.youtube.com/watch?v=Pujol1yC1_A)\n",
    "**Defination** :\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why use it?\n",
    "\n",
    "When the sample taken from population is generally normally distribution.\n",
    "\n",
    "The distribution of mean of samples drawn from population, its always normal\n",
    "\n",
    "As sample size increases the distribution will be more towards normal.\n",
    "\n",
    "As number of samples increase, the distribution of mean of samples will be more towards normal.\n",
    "\n",
    "\n",
    "> samples must be drawn randomly\n",
    "\n",
    "> distribution of population data may or may not be normal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05.07.2024 Class\n",
    "\n",
    "# Excel\n",
    "it is still relevent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "play with strings\n",
    "\n",
    "make plots to understand data\n",
    "\n",
    "check central tendencies\n",
    "\n",
    "check na\n",
    "\n",
    "fillna\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt](Images/impExcelFunctions.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 09.07.2024 Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
